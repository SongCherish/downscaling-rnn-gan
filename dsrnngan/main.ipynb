{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "import plots\n",
    "import train\n",
    "\n",
    "\n",
    "path = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('mode', type=str, help=\"train or plot\")\n",
    "    parser.add_argument('--data_file', type=str, \n",
    "        help=\"Training data file\")\n",
    "    parser.add_argument('--test_data_file', type=str, default=\"\",\n",
    "        help=\"Test data file\")\n",
    "    parser.add_argument('--application', type=str, default=\"mchrzc\",\n",
    "        help=\"Network weights file root to load\")\n",
    "    parser.add_argument('--load_weights_root', type=str, default=\"\",\n",
    "        help=\"Network weights file root to load\")\n",
    "    parser.add_argument('--save_weights_root', type=str, default=\"\",\n",
    "        help=\"Network weights file root to save\")\n",
    "    parser.add_argument('--log_path', type=str, default=\"\",\n",
    "        help=\"Log files path\")\n",
    "    parser.add_argument('--steps_per_epoch', type=int, default=200,\n",
    "        help=\"Batches per epoch\")\n",
    "    parser.add_argument('--batch_size', type=int, default=16,\n",
    "        help=\"Batch size\")\n",
    "    parser.add_argument('--num_samples', type=int, default=400000,\n",
    "        help=\"Training samples\")\n",
    "    parser.add_argument('--opt_switch_point', type=int, default=350000,\n",
    "        help=\"The num. of samples at which the optimizer is switched to SGD\")\n",
    "    parser.add_argument('--mchrzc_data_file', type=str, default=\"\",\n",
    "        help=\"MCH-RZC data file\")\n",
    "    parser.add_argument('--goescod_data_file', type=str, default=\"\",\n",
    "        help=\"GOES-COT data file\")\n",
    "        \n",
    "    args = parser.parse_args()\n",
    "    mode = args.mode\n",
    "\n",
    "    if mode==\"train\":\n",
    "\n",
    "        data_fn = args.data_file\n",
    "        application = args.application\n",
    "        load_weights_root = args.load_weights_root\n",
    "        save_weights_root = args.save_weights_root\n",
    "        log_path = args.log_path\n",
    "        steps_per_epoch = args.steps_per_epoch\n",
    "        batch_size = args.batch_size\n",
    "        num_samples = args.num_samples\n",
    "        opt_switch_point = args.opt_switch_point\n",
    "\n",
    "        if not save_weights_root:\n",
    "            save_weights_root = path + \"../models/downscaleseqgan\"\n",
    "\n",
    "        # initialize GAN\n",
    "        (wgan, batch_gen_train, batch_gen_valid, _, noise_shapes, _) = \\\n",
    "            train.setup_gan(data_fn, \n",
    "                batch_size=batch_size, application=application)\n",
    "\n",
    "        if load_weights_root: # load weights and run status\n",
    "            wgan.load(wgan.filenames_from_root(load_weights_root))\n",
    "            with open(load_weights_root+\"-run_status.json\", 'r') as f:\n",
    "                run_status = json.load(f)\n",
    "            training_samples = run_status[\"training_samples\"]\n",
    "\n",
    "            if log_path:\n",
    "                log_file = \"{}/log-{}.txt\".format(log_path, application)\n",
    "                log = pd.read_csv(log_file)\n",
    "\n",
    "        else: # initialize run status\n",
    "            chars = string.ascii_lowercase + string.digits\n",
    "            training_samples = 0\n",
    "\n",
    "            if log_path:\n",
    "                log_file = \"{}/log-{}.txt\".format(log_path, application)\n",
    "                log = pd.DataFrame(columns=[\"training_samples\", \n",
    "                    \"disc_loss\", \"disc_loss_real\", \"disc_loss_fake\",\n",
    "                    \"disc_loss_gp\", \"gen_loss\"])\n",
    "\n",
    "        plot_fn = \"{}/progress-{}.pdf\".format(log_path,application) if log_path \\\n",
    "            else path+\"/../figures/progress.pdf\"\n",
    "        switched_opt = (training_samples >= opt_switch_point)\n",
    "\n",
    "        while (training_samples < num_samples): # main training loop\n",
    "\n",
    "            # check if we should switch optimizers\n",
    "            if (training_samples >= opt_switch_point) and not switched_opt:\n",
    "                opt_disc = SGD(1e-5)\n",
    "                opt_gen = SGD(1e-5)\n",
    "                wgan.compile(opt_disc=opt_disc, opt_gen=opt_gen)\n",
    "                switched_opt = True\n",
    "\n",
    "            # train for some number of batches\n",
    "            loss_log = train.train_gan(wgan, batch_gen_train,\n",
    "                batch_gen_valid, noise_shapes,\n",
    "                steps_per_epoch, 1, plot_fn=plot_fn)\n",
    "            loss_log = np.mean(loss_log, axis=0)\n",
    "            training_samples += steps_per_epoch * batch_gen_train.batch_size\n",
    "\n",
    "            # save results\n",
    "            wgan.save(save_weights_root)\n",
    "            run_status = {\n",
    "                \"application\": application,\n",
    "                \"training_samples\": training_samples,\n",
    "            }\n",
    "            with open(save_weights_root+\"-run_status.json\", 'w') as f:\n",
    "                json.dump(run_status, f)\n",
    "\n",
    "            if log_path: # log losses and generator weights for evaluation\n",
    "                log = log.append(pd.DataFrame(data={\n",
    "                    \"training_samples\": [training_samples],\n",
    "                    \"disc_loss\": [loss_log[0]],\n",
    "                    \"disc_loss_real\": [loss_log[1]],\n",
    "                    \"disc_loss_fake\": [loss_log[2]],\n",
    "                    \"disc_loss_gp\": [loss_log[3]],\n",
    "                    \"gen_loss\": [loss_log[4]]\n",
    "                }))\n",
    "                log.to_csv(log_file, index=False, float_format=\"%.6f\")\n",
    "                        \n",
    "                gen_weights_file = \"{}/gen_weights-{}-{:07d}.h5\".format(\n",
    "                    log_path, application, training_samples)\n",
    "                wgan.gen.save_weights(gen_weights_file)\n",
    "\n",
    "\n",
    "    elif mode == \"plot\":\n",
    "        mchrzc_data_fn = args.mchrzc_data_file\n",
    "        goescod_data_fn = args.goescod_data_file\n",
    "\n",
    "        plots.plot_all(mchrzc_data_fn, goescod_data_fn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
